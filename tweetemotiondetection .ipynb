{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effa1148",
   "metadata": {},
   "source": [
    "# Emotion detection using Deep Learning\n",
    "## By: Kirti Agarwal and Karan Kakadiya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf04c0",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22807486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e8ea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge keras-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6284ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Keras-Preprocessing\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.23.5)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "Installing collected packages: Keras-Preprocessing\n",
      "Successfully installed Keras-Preprocessing-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e58056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\RAKESH\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras-preprocessing\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.12.7  |       h5b45459_0         143 KB  conda-forge\n",
      "    certifi-2022.12.7          |     pyhd8ed1ab_0         147 KB  conda-forge\n",
      "    keras-preprocessing-1.1.2  |     pyhd8ed1ab_0          34 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         325 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.2-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.01.10~ --> conda-forge::ca-certificates-2022.12.7-h5b45459_0 \n",
      "  certifi            pkgs/main/win-64::certifi-2022.12.7-p~ --> conda-forge/noarch::certifi-2022.12.7-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "ca-certificates-2022 | 143 KB    |            |   0% \n",
      "\n",
      "keras-preprocessing- | 34 KB     |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 147 KB    |            |   0% \u001b[A\u001b[A\n",
      "ca-certificates-2022 | 143 KB    | #1         |  11% \n",
      "\n",
      "keras-preprocessing- | 34 KB     | ####6      |  47% \u001b[A\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 147 KB    | #          |  11% \u001b[A\u001b[A\n",
      "ca-certificates-2022 | 143 KB    | ###3       |  34% \n",
      "\n",
      "keras-preprocessing- | 34 KB     | ########## | 100% \u001b[A\n",
      "\n",
      "keras-preprocessing- | 34 KB     | ########## | 100% \u001b[A\n",
      "ca-certificates-2022 | 143 KB    | #####5     |  56% \n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 147 KB    | ###2       |  33% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 147 KB    | #####4     |  54% \u001b[A\u001b[A\n",
      "ca-certificates-2022 | 143 KB    | #######8   |  78% \n",
      "ca-certificates-2022 | 143 KB    | ########## | 100% \n",
      "ca-certificates-2022 | 143 KB    | ########## | 100% \n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 147 KB    | #######6   |  76% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 147 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 147 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting TensorFlow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "     ------------------------------------ 272.8/272.8 MB 452.5 kB/s eta 0:00:00\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.8.tar.gz (1.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: packaging in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (22.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (2.12.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (1.23.5)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (4.4.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (65.6.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.22.3-cp310-abi3-win_amd64.whl (420 kB)\n",
      "     ------------------------------------ 420.6/420.6 kB 597.4 kB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 755.8 kB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.0-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 717.9 kB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->TensorFlow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->TensorFlow) (0.38.4)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Downloading ml_dtypes-0.1.0-cp310-cp310-win_amd64.whl (120 kB)\n",
      "     ------------------------------------ 120.4/120.4 kB 781.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->TensorFlow) (1.10.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (2.28.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (3.4.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (2.2.2)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->TensorFlow) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\rakesh\\\\anaconda3\\\\lib\\\\site-packages\\\\certifi-2022.12.7.dist-info\\\\METADATA'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64726ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting livelossplot\n",
      "  Using cached livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from livelossplot) (3.7.0)\n",
      "Requirement already satisfied: bokeh in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from livelossplot) (2.4.3)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (1.23.5)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (6.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (3.1.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (9.4.0)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (6.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (1.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rakesh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
      "Installing collected packages: livelossplot\n",
      "Successfully installed livelossplot-0.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bb5d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aaea9d",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a7d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d51d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "def load_dataset(filename):\n",
    "  df = pd.read_csv(filename)\n",
    "  label = df[\"label\"]\n",
    "  unique_label = list(set(label))\n",
    "  sentences = list(df[\"text\"])\n",
    "  \n",
    "  return (df, label, unique_label, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64bb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, label, unique_label, sentences = load_dataset(r'D:\\adypu\\INTERSHIP\\project\\adani twitter\\emotionsentiment\\emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9335d00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text Unnamed: 2\n",
       "0      joy  On days when I feel close to my partner and ot...        NaN\n",
       "1     fear  Every time I imagine that someone I love or I ...        NaN\n",
       "2    anger  When I had been obviously unjustly treated and...        NaN\n",
       "3  sadness  When I think about the short time that we live...        NaN\n",
       "4  disgust  At a gathering I found myself involuntarily si...        NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde45b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness', 'guilt', 'disgust', 'fear', 'joy', 'shame', 'anger']\n"
     ]
    }
   ],
   "source": [
    "unique_label = list(set(label))\n",
    "print(unique_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba5e717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import tkinter\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.countplot(x=\"label\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70de20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['On days when I feel close to my partner and other friends.   \\nWhen I feel at peace with myself and also experience a close  \\ncontact with people whom I regard greatly.', 'Every time I imagine that someone I love or I could contact a  \\nserious illness, even death.', 'When I had been obviously unjustly treated and had no possibility  \\nof elucidating this.', 'When I think about the short time that we live and relate it to  \\nthe periods of my life when I think that I did not use this  \\nshort time.', 'At a gathering I found myself involuntarily sitting next to two  \\npeople who expressed opinions that I considered very low and  \\ndiscriminating.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a220674b",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79f0360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792274e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define stemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57c1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "  words = []\n",
    "  for s in sentences:\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
    "    w = word_tokenize(clean)\n",
    "    words.append([i.lower() for i in w])\n",
    "    \n",
    "  return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25f3e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7516\n",
      "[['on', 'days', 'when', 'i', 'feel', 'close', 'to', 'my', 'partner', 'and', 'other', 'friends', 'when', 'i', 'feel', 'at', 'peace', 'with', 'myself', 'and', 'also', 'experience', 'a', 'close', 'contact', 'with', 'people', 'whom', 'i', 'regard', 'greatly'], ['every', 'time', 'i', 'imagine', 'that', 'someone', 'i', 'love', 'or', 'i', 'could', 'contact', 'a', 'serious', 'illness', 'even', 'death']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))\n",
    "print(cleaned_words[:2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5825cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "  token = Tokenizer(filters = filters)\n",
    "  token.fit_on_texts(words)\n",
    "  return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41c66b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "  return(len(max(words, key = len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "852b2b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 8989 and Maximum length = 179\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca5ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "  return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00d4b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ca711e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80539763",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fb35785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (7516, 179)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6a617d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_label, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc4cd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sadness': 1,\n",
       " 'guilt': 2,\n",
       " 'disgust': 3,\n",
       " 'fear': 4,\n",
       " 'joy': 5,\n",
       " 'shame': 6,\n",
       " 'anger': 7}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6371e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24e00033",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f688fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7516, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0126efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "  o = OneHotEncoder(sparse = False)\n",
    "  return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a4bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAKESH\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ac52469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7516, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056a131",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f095647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24a41a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "597c4053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (6012, 179) and train_Y = (6012, 7)\n",
      "Shape of val_X = (1504, 179) and val_Y = (1504, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "521ee165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(GRU(128)))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(7, activation = \"softmax\"))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d5a86a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 179, 128)          1150592   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              198144    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,357,191\n",
      "Trainable params: 206,599\n",
      "Non-trainable params: 1,150,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_length)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d5e3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17cc0d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 14/188 [=>............................] - ETA: 2:14 - loss: 1.9494 - accuracy: 0.1317"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mPlotLossesKeras\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_X, train_Y,\n",
    "                 epochs = 100,\n",
    "                 batch_size = 32,\n",
    "                 validation_data = (val_X, val_Y),\n",
    "                 callbacks = [PlotLossesKeras(), checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e514a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 179, 128)          1150592   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              263168    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,422,215\n",
      "Trainable params: 271,623\n",
      "Non-trainable params: 1,150,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(LSTM(128)))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(7, activation = \"softmax\"))\n",
    "  \n",
    "  return model\n",
    "\n",
    "model_lstm = create_model(vocab_size, max_length)\n",
    "\n",
    "model_lstm.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b02c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_lstm.h5'\n",
    "checkpoint = ModelCheckpoint(filename,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "hist = model_lstm.fit(train_X, train_Y,\n",
    "                 epochs = 100,\n",
    "                 batch_size = 32,\n",
    "                 validation_data = (val_X, val_Y),\n",
    "                 callbacks = [PlotLossesKeras(), checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_lstm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd73c0",
   "metadata": {},
   "source": [
    "## Prediction of Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57bcb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "  clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "  test_word = word_tokenize(clean)\n",
    "  test_word = [w.lower() for w in test_word]\n",
    "  test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "\n",
    "  if [] in test_ls:\n",
    "    test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    "  x = padding_doc(test_ls, max_length)\n",
    "\n",
    "  pred = model.predict(x)\n",
    "  \n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc997a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "  predictions = pred[0]\n",
    "  classes = np.array(classes)\n",
    "  ids = np.argsort(-predictions)\n",
    "  classes = classes[ids]\n",
    "  predictions = -np.sort(-predictions)\n",
    " \n",
    "  for i in range(pred.shape[1]):\n",
    "    print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "  \n",
    "  return classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03aac5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(text):\n",
    "    pred = predictions(text)\n",
    "    result = get_final_output(pred, unique_label)\n",
    "    print('\\nans: {}\\n'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30bbdfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "anger has confidence = 0.14649513\n",
      "fear has confidence = 0.14579144\n",
      "disgust has confidence = 0.1448504\n",
      "joy has confidence = 0.14220335\n",
      "guilt has confidence = 0.14214952\n",
      "sadness has confidence = 0.14000422\n",
      "shame has confidence = 0.13850592\n",
      "\n",
      "ans: anger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_emotion(\"I did not help out enough at my thesis team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a30e54",
   "metadata": {},
   "source": [
    "## Tkinter GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00098d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "fear has confidence = 0.1461465\n",
      "joy has confidence = 0.14463592\n",
      "disgust has confidence = 0.14324184\n",
      "sadness has confidence = 0.14227454\n",
      "anger has confidence = 0.1419598\n",
      "guilt has confidence = 0.14137289\n",
      "shame has confidence = 0.14036849\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "\n",
    "def get_emotion():\n",
    "    text = input_box.get(\"1.0\", \"end-1c\")\n",
    "    pred = predictions(text)\n",
    "    result = get_final_output(pred, unique_label)\n",
    "    output_window = tk.Toplevel(window)\n",
    "    output_window.title(\"Emotion Detected\")\n",
    "    output_label = tk.Label(output_window, text=result)\n",
    "    output_label.pack()\n",
    "\n",
    "# Create GUI window\n",
    "window = tk.Tk()\n",
    "window.title(\"Emotion Detection\")\n",
    "\n",
    "# Create input box\n",
    "input_box = tk.Text(window, height=10, width=50)\n",
    "input_box.pack()\n",
    "\n",
    "# Create button\n",
    "button = tk.Button(window, text=\"Detect Emotion\", command=get_emotion)\n",
    "button.pack()\n",
    "\n",
    "# Start GUI\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027074b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
